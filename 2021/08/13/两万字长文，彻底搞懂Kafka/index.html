<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 5.4.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"chenjiabing666.github.io","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="1、为什么有消息系统1、解耦合2、异步处理例如电商平台，秒杀活动。">
<meta property="og:type" content="article">
<meta property="og:title" content="两万字长文，彻底搞懂Kafka">
<meta property="og:url" content="https://chenjiabing666.github.io/2021/08/13/%E4%B8%A4%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%EF%BC%8C%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82Kafka/index.html">
<meta property="og:site_name" content="不才陈某技术博客">
<meta property="og:description" content="1、为什么有消息系统1、解耦合2、异步处理例如电商平台，秒杀活动。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/18.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/1.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/2.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/3.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/4.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/5.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/6.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/7.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/8.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/9.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/10.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/11.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/12.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/13.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/14.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/15.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/16.png">
<meta property="og:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/17.png">
<meta property="article:published_time" content="2021-08-13T01:22:57.000Z">
<meta property="article:modified_time" content="2021-08-13T01:31:21.371Z">
<meta property="article:author" content="不才陈某">
<meta property="article:tag" content="kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/18.png">

<link rel="canonical" href="https://chenjiabing666.github.io/2021/08/13/%E4%B8%A4%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%EF%BC%8C%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82Kafka/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>两万字长文，彻底搞懂Kafka | 不才陈某技术博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">不才陈某技术博客</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">微信公众号：码猿技术专栏</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
		<div id="container">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://chenjiabing666.github.io/2021/08/13/%E4%B8%A4%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%EF%BC%8C%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82Kafka/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/header.jpg">
      <meta itemprop="name" content="不才陈某">
      <meta itemprop="description" content="本站是不才陈某的技术分享博客。内容涵盖Java后端技术、Spring Boot、微服务架构、系统安全、前端、系统监控等相关的研究与知识分享。">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="不才陈某技术博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          两万字长文，彻底搞懂Kafka
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>
              

              <time title="创建时间：2021-08-13 09:22:57 / 修改时间：09:31:21" itemprop="dateCreated datePublished" datetime="2021-08-13T09:22:57+08:00">2021-08-13</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/" itemprop="url" rel="index"><span itemprop="name">消息队列</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
  
  <span class="post-meta-item">
    
      <span class="post-meta-item-icon">
        <i class="far fa-comment"></i>
      </span>
      <span class="post-meta-item-text">Valine：</span>
    
    <a title="valine" href="/2021/08/13/%E4%B8%A4%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%EF%BC%8C%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82Kafka/#valine-comments" itemprop="discussionUrl">
      <span class="post-comments-count valine-comment-count" data-xid="/2021/08/13/%E4%B8%A4%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%EF%BC%8C%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82Kafka/" itemprop="commentCount"></span>
    </a>
  </span>
  
  

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="1、为什么有消息系统"><a href="#1、为什么有消息系统" class="headerlink" title="1、为什么有消息系统"></a>1、为什么有消息系统</h2><h5 id="1、解耦合"><a href="#1、解耦合" class="headerlink" title="1、解耦合"></a>1、解耦合</h5><h5 id="2、异步处理"><a href="#2、异步处理" class="headerlink" title="2、异步处理"></a>2、异步处理</h5><p>例如电商平台，秒杀活动。</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/18.png"></p>
<span id="more"></span>

<p>一般流程会分为：</p>
<ol>
<li>风险控制</li>
<li>库存锁定</li>
<li>生成订单</li>
<li>短信通知</li>
<li>更新数据</li>
</ol>
<p>通过消息系统将秒杀活动业务拆分开，将不急需处理的业务放在后面慢慢处理；</p>
<p>流程改为：</p>
<ol>
<li>风险控制</li>
<li>库存锁定</li>
<li>消息系统</li>
<li>生成订单</li>
<li>短信通知</li>
<li>更新数据</li>
</ol>
<h5 id="3、流量的控制"><a href="#3、流量的控制" class="headerlink" title="3、流量的控制"></a>3、流量的控制</h5><p>3.1 网关在接受到请求后，就把请求放入到消息队列里面</p>
<p>3.2 后端的服务从消息队列里面获取到请求，完成后续的秒杀处理流程。然后再给用户返回结果。</p>
<ul>
<li>优点：控制了流量</li>
<li>缺点：会让流程变慢</li>
</ul>
<h2 id="2、Kafka核心概念"><a href="#2、Kafka核心概念" class="headerlink" title="2、Kafka核心概念"></a>2、Kafka核心概念</h2><ul>
<li>生产者：Producer 往Kafka集群生成数据</li>
<li>消费者：Consumer 往Kafka里面去获取数据，处理数据、消费数据</li>
</ul>
<p>Kafka的数据是由消费者自己去拉去Kafka里面的数据</p>
<ul>
<li>主题：topic</li>
<li>分区：partition</li>
</ul>
<p>默认一个topic有一个分区（partition），自己可设置多个分区（分区分散存储在服务器不同节点上）</p>
<p>解决了一个海量数据如何存储的问题</p>
<p>例如：有2T的数据，一台服务器有1T，一个topic可以分多个区，分别存储在多台服务器上，解决海量数据存储问题</p>
<h2 id="3、Kafka的集群架构"><a href="#3、Kafka的集群架构" class="headerlink" title="3、Kafka的集群架构"></a>3、Kafka的集群架构</h2><p>Kafka集群中，一个kafka服务器就是一个broker，Topic只是逻辑上的概念，partition在磁盘上就体现为一个目录。</p>
<p>Consumer Group：消费组，消费数据的时候，都必须指定一个group id，指定一个组的id</p>
<p>假定程序A和程序B指定的group id号一样，那么两个程序就属于同一个消费组</p>
<p>特殊：</p>
<ul>
<li>比如，有一个主题topicA， 程序A去消费了这个topicA，那么程序B就不能再去消费topicA（程序A和程序B属于一个消费组）</li>
<li>再比如程序A已经消费了topicA里面的数据，现在还是重新再次消费topicA的数据，是不可以的，但是重新指定一个group id号以后，可以消费。</li>
</ul>
<p>不同消费组之间没有影响。消费组需自定义，消费者名称程序自动生成（独一无二）。</p>
<p>Controller：Kafka节点里面的一个主节点。借助zookeeper</p>
<h2 id="4、Kafka磁盘顺序写保证写数据性能"><a href="#4、Kafka磁盘顺序写保证写数据性能" class="headerlink" title="4、Kafka磁盘顺序写保证写数据性能"></a>4、Kafka磁盘顺序写保证写数据性能</h2><p>kafka写数据：</p>
<p>顺序写，往磁盘上写数据时，就是追加数据，没有随机写的操作。</p>
<p>经验：</p>
<p>如果一个服务器磁盘达到一定的个数，磁盘也达到一定转数，往磁盘里面顺序写（追加写）数据的速度和写内存的速度差不多。</p>
<p>生产者生产消息，经过kafka服务先写到os cache 内存中，然后经过sync顺序写到磁盘上</p>
<h2 id="5、Kafka零拷贝机制保证读数据高性能"><a href="#5、Kafka零拷贝机制保证读数据高性能" class="headerlink" title="5、Kafka零拷贝机制保证读数据高性能"></a>5、Kafka零拷贝机制保证读数据高性能</h2><p>消费者读取数据流程：</p>
<ol>
<li>消费者发送请求给kafka服务</li>
<li>kafka服务去os cache缓存读取数据（缓存没有就去磁盘读取数据）</li>
<li>从磁盘读取了数据到os cache缓存中</li>
<li>os cache复制数据到kafka应用程序中</li>
<li>kafka将数据（复制）发送到socket cache中</li>
<li>socket cache通过网卡传输给消费者</li>
</ol>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/1.png"></p>
<p>kafka linux sendfile技术 — 零拷贝</p>
<ol>
<li>消费者发送请求给kafka服务</li>
<li>kafka服务去os cache缓存读取数据（缓存没有就去磁盘读取数据）</li>
<li>从磁盘读取了数据到os cache缓存中</li>
<li>os cache直接将数据发送给网卡</li>
<li>通过网卡将数据传输给消费者</li>
</ol>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/2.png"></p>
<h2 id="6、Kafka日志分段保存"><a href="#6、Kafka日志分段保存" class="headerlink" title="6、Kafka日志分段保存"></a>6、Kafka日志分段保存</h2><p>Kafka中一个主题，一般会设置分区；比如创建了一个topic_a，然后创建的时候指定了这个主题有三个分区。</p>
<p>其实在三台服务器上，会创建三个目录。</p>
<p>服务器1（kafka1）：</p>
<ul>
<li>创建目录topic_a-0:</li>
<li>目录下面是我们文件（存储数据），kafka数据就是message，数据存储在log文件里</li>
<li>.log结尾的就是日志文件，在kafka中把数据文件就叫做日志文件。</li>
</ul>
<p>一个分区下面默认有n多个日志文件（分段存储），一个日志文件默认1G</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/3.png"></p>
<p>服务器2（kafka2）：</p>
<ul>
<li>创建目录topic_a-1:</li>
</ul>
<p>服务器3（kafka3）：</p>
<ul>
<li>创建目录topic_a-2:</li>
</ul>
<h2 id="7、Kafka二分查找定位数据"><a href="#7、Kafka二分查找定位数据" class="headerlink" title="7、Kafka二分查找定位数据"></a>7、Kafka二分查找定位数据</h2><p>Kafka里面每一条消息，都有自己的offset（相对偏移量），存在物理磁盘上面，在position</p>
<p>Position：物理位置（磁盘上面那个地方）</p>
<p>也就是说一条消息就有两个位置：</p>
<ul>
<li>offset：相对偏移量（相对位置）</li>
<li>position：磁盘物理位置</li>
</ul>
<p>稀疏索引：</p>
<ul>
<li>Kafka中采用了稀疏索引的方式读取索引，kafka每当写入了4k大小的日志（.log），就往index里写入一个记录索引。</li>
</ul>
<p>其中会采用二分查找</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/4.png"></p>
<h2 id="8、高并发网络设计（先了解NIO）"><a href="#8、高并发网络设计（先了解NIO）" class="headerlink" title="8、高并发网络设计（先了解NIO）"></a>8、高并发网络设计（先了解NIO）</h2><p>网络设计部分是kafka中设计最好的一个部分，这也是保证Kafka高并发、高性能的原因</p>
<p>对kafka进行调优，就得对kafka原理比较了解，尤其是网络设计部分</p>
<p>Reactor网络设计模式1：</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/5.png"></p>
<p>Reactor网络设计模式2：</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/6.png"></p>
<p>Reactor网络设计模式3：</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/7.png"></p>
<p>Kafka超高并发网络设计：</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/8.png"></p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/9.png"></p>
<h2 id="9、Kafka冗余副本保证高可用"><a href="#9、Kafka冗余副本保证高可用" class="headerlink" title="9、Kafka冗余副本保证高可用"></a>9、Kafka冗余副本保证高可用</h2><p>在kafka里面分区是有副本的，注：0.8以前是没有副本机制的。创建主题时，可以指定分区，也可以指定副本个数。副本是有角色的：</p>
<p>leader partition：</p>
<ul>
<li>写数据、读数据操作都是从leader partition去操作的。</li>
<li>会维护一个ISR（in-sync- replica ）列表，但是会根据一定的规则删除ISR列表里面的值</li>
</ul>
<p>生产者发送来一个消息，消息首先要写入到leader partition中</p>
<p>写完了以后，还要把消息写入到ISR列表里面的其它分区，写完后才算这个消息提交</p>
<p>follower partition：从leader partition同步数据。</p>
<h2 id="10、优秀架构思考-总结"><a href="#10、优秀架构思考-总结" class="headerlink" title="10、优秀架构思考-总结"></a>10、优秀架构思考-总结</h2><p>Kafka — 高并发、高可用、高性能</p>
<ul>
<li>高可用：多副本机制</li>
<li>高并发：网络架构设计 三层架构：多selector -&gt; 多线程 -&gt; 队列的设计（NIO）</li>
<li>高性能：</li>
</ul>
<p>写数据：</p>
<ol>
<li>把数据先写入到OS Cache</li>
<li>写到磁盘上面是顺序写，性能很高</li>
</ol>
<p>读数据：</p>
<ol>
<li><p>根据稀疏索引，快速定位到要消费的数据</p>
</li>
<li><p>零拷贝机制</p>
</li>
<li><ul>
<li>减少数据的拷贝</li>
<li>减少了应用程序与操作系统上下文切换</li>
</ul>
</li>
</ol>
<h2 id="11、Kafka生产环境搭建"><a href="#11、Kafka生产环境搭建" class="headerlink" title="11、Kafka生产环境搭建"></a>11、Kafka生产环境搭建</h2><h4 id="11-1-需求场景分析"><a href="#11-1-需求场景分析" class="headerlink" title="11.1 需求场景分析"></a>11.1 需求场景分析</h4><p>电商平台，需要每天10亿请求都要发送到Kafka集群上面。二八反正，一般评估出来问题都不大。</p>
<p>10亿请求 -&gt; 24 过来的，一般情况下，每天的12:00 到早上8:00 这段时间其实是没有多大的数据量的。80%的请求是用的另外16小时的处理的。16个小时处理 -&gt; 8亿的请求。16 * 0.2 = 3个小时 处理了8亿请求的80%的数据</p>
<p>也就是说6亿的数据是靠3个小时处理完的。我们简单的算一下高峰期时候的qps</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">6</span>亿/<span class="number">3</span>小时 =<span class="number">5.5</span>万/s qps=<span class="number">5.5</span>万</span><br></pre></td></tr></table></figure>

<p><code>10亿请求 * 50kb = 46T</code> 每天需要存储46T的数据</p>
<p>一般情况下，我们都会设置两个副本 <code>46T * 2 = 92T</code>，Kafka里面的数据是有保留的时间周期，保留最近3天的数据。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">92T * <span class="number">3</span>天 = 276T</span><br></pre></td></tr></table></figure>

<p>我这儿说的是50kb不是说一条消息就是50kb不是（把日志合并了，多条日志合并在一起），通常情况下，一条消息就几b，也有可能就是几百字节。</p>
<h4 id="11-2-物理机数量评估"><a href="#11-2-物理机数量评估" class="headerlink" title="11.2 物理机数量评估"></a>11.2 物理机数量评估</h4><p>1）首先分析一下是需要虚拟机还是物理机</p>
<p>像Kafka mysql hadoop这些集群搭建的时候，我们生产里面都是使用物理机。</p>
<p>2）高峰期需要处理的请求总的请求每秒5.5万个，其实一两台物理机绝对是可以抗住的。一般情况下，我们评估机器的时候，是按照高峰期的4倍的去评估。</p>
<p>如果是4倍的话，大概我们集群的能力要准备到 20万qps。这样子的集群才是比较安全的集群。大概就需要5台物理机。每台承受4万请求。</p>
<p>场景总结：</p>
<ul>
<li>搞定10亿请求，高峰期5.5万的qps,276T的数据，需要5台物理机。</li>
</ul>
<h4 id="11-3-磁盘选择"><a href="#11-3-磁盘选择" class="headerlink" title="11.3 磁盘选择"></a>11.3 磁盘选择</h4><p>搞定10亿请求，高峰期5.5万的qps,276T的数据，需要5台物理机。</p>
<p>1）SSD固态硬盘，还是需要普通的机械硬盘</p>
<ul>
<li>SSD硬盘：性能比较好，但是价格贵</li>
<li>SAS盘：某方面性能不是很好，但是比较便宜。</li>
</ul>
<p>SSD硬盘性能比较好，指的是它随机读写的性能比较好。适合MySQL这样集群。</p>
<p>但是其实他的顺序写的性能跟SAS盘差不多。</p>
<p>kafka的理解：就是用的顺序写。所以我们就用普通的【机械硬盘】就可以了。</p>
<p>2）需要我们评估每台服务器需要多少块磁盘</p>
<p>5台服务器，一共需要276T ，大约每台服务器 需要存储60T的数据。我们公司里面服务器的配置用的是 11块硬盘，每个硬盘 7T。<code>11 * 7T = 77T</code></p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">77T * <span class="number">5</span> 台服务器 = 385T</span><br></pre></td></tr></table></figure>

<p>场景总结：</p>
<ul>
<li>搞定10亿请求，需要5台物理机，11（SAS） * 7T</li>
</ul>
<p>11.4 内存评估 搞定10亿请求，需要5台物理机，<code>11（SAS） * 7T</code></p>
<p>我们发现kafka读写数据的流程 都是基于os cache,换句话说假设咱们的os cashe无限大那么整个kafka是不是相当于就是基于内存去操作，如果是基于内存去操作，性能肯定很好。内存是有限的。</p>
<ul>
<li>尽可能多的内存资源要给 os cache</li>
<li>Kafka的代码用 核心的代码用的是scala写的，客户端的代码java写的。都是基于jvm。所以我们还要给一部分的内存给jvm。</li>
</ul>
<p>Kafka的设计，没有把很多数据结构都放在jvm里面。所以我们的这个jvm不需要太大的内存。根据经验，给个10G就可以了。</p>
<p>NameNode:jvm里面还放了元数据（几十G），JVM一定要给得很大。比如给个100G。</p>
<p>假设我们这个10请求的这个项目，一共会有100个topic。<code>100 topic * 5 partition * 2 = 1000 partition</code></p>
<p>一个partition其实就是物理机上面的一个目录，这个目录下面会有很多个.log的文件。</p>
<ul>
<li>.log就是存储数据文件，默认情况下一个.log文件的大小是1G。</li>
</ul>
<p>我们如果要保证 1000个partition 的最新的.log 文件的数据 如果都在内存里面，这个时候性能就是最好。<code>1000 * 1G = 1000G</code>内存.</p>
<p>我们只需要把当前最新的这个log 保证里面的25%的最新的数据在内存里面。<code>250M * 1000 = 0.25 G* 1000 =250G</code>的内存。</p>
<ul>
<li><code>250内存 / 5 = 50G</code>内存</li>
<li><code>50G+10G = 60G</code>内存</li>
</ul>
<p>64G的内存，另外的4G，操作系统本生是不是也需要内存。其实Kafka的jvm也可以不用给到10G这么多。评估出来64G是可以的。当然如果能给到128G的内存的服务器，那就最好。</p>
<p>我刚刚评估的时候用的都是一个topic是5个partition，但是如果是数据量比较大的topic，可能会有10个partition。</p>
<p>总结：</p>
<ul>
<li>搞定10亿请求，需要5台物理机，<code>11（SAS） * 7T</code> ，需要64G的内存（128G更好）</li>
</ul>
<h4 id="11-5-CPU压力评估"><a href="#11-5-CPU压力评估" class="headerlink" title="11.5 CPU压力评估"></a>11.5 CPU压力评估</h4><p>评估一下每台服务器需要多少cpu core(资源很有限)</p>
<p>我们评估需要多少个cpu ，依据就是看我们的服务里面有多少线程去跑。线程就是依托cpu 去运行的。如果我们的线程比较多，但是cpu core比较少，这样的话，我们的机器负载就会很高，性能不就不好。</p>
<p>评估一下，kafka的一台服务器 启动以后会有多少线程？</p>
<ul>
<li>Acceptor线程 1</li>
<li>processor线程 3 6~9个线程</li>
<li>处理请求线程 8个 32个线程</li>
<li>定时清理的线程，拉取数据的线程，定时检查ISR列表的机制 等等。</li>
</ul>
<p>所以大概一个Kafka的服务启动起来以后，会有一百多个线程。</p>
<ul>
<li>cpu core = 4个，一遍来说，几十个线程，就肯定把cpu 打满了。</li>
<li>cpu core = 8个，应该很轻松的能支持几十个线程。</li>
</ul>
<p>如果我们的线程是100多个，或者差不多200个，那么8 个 cpu core是搞不定的。</p>
<p>另外关注公众号码猿技术专栏，回复关键词“面试宝典”，送你一份阿里内部面试资料！</p>
<p>所以我们这儿建议：</p>
<ul>
<li>CPU core = 16个。如果可以的话，能有32个cpu core 那就最好。</li>
</ul>
<p>结论：</p>
<ul>
<li>kafka集群，最低也要给16个cpu core，如果能给到32 cpu core那就更好。</li>
<li><code>2cpu * 8 =16</code> cpu core</li>
<li><code>4cpu * 8 = 32</code> cpu core</li>
</ul>
<p>总结：</p>
<ul>
<li>搞定10亿请求，需要5台物理机， <code>11（SAS） * 7T</code> ，需要64G的内存（128G更好），需要16个cpu core（32个更好）</li>
</ul>
<h3 id="11-6-网络需求评估"><a href="#11-6-网络需求评估" class="headerlink" title="11.6 网络需求评估"></a>11.6 网络需求评估</h3><p>评估我们需要什么样网卡？</p>
<p>一般要么是千兆的网卡（1G/s），还有的就是万兆的网卡（10G/s）</p>
<p>高峰期的时候 每秒会有5.5万的请求涌入，5.5/5 = 大约是每台服务器会有1万个请求涌入。我们之前说的，<code>10000 * 50kb = 488M</code> 也就是每条服务器，每秒要接受488M的数据。数据还要有副本，副本之间的同步，也是走的网络的请求。<code>488 * 2 = 976m/s</code></p>
<p>说明一下：</p>
<ul>
<li>很多公司的数据，一个请求里面是没有50kb这么大的，我们公司是因为主机在生产端封装了数据，然后把多条数据合并在一起了，所以我们的一个请求才会有这么大。</li>
<li>一般情况下，网卡的带宽是达不到极限的，如果是千兆的网卡，我们能用的一般就是700M左右。但是如果最好的情况，我们还是使用万兆的网卡。</li>
<li>如果使用的是万兆的，那就是很轻松。</li>
</ul>
<h4 id="11-7-集群规划"><a href="#11-7-集群规划" class="headerlink" title="11.7 集群规划"></a>11.7 集群规划</h4><ul>
<li>请求量</li>
<li>规划物理机的个数</li>
<li>分析磁盘的个数，选择使用什么样的磁盘</li>
<li>内存</li>
<li>cpu core</li>
<li>网卡</li>
</ul>
<p>就是告诉大家，以后要是公司里面有什么需求，进行资源的评估，服务器的评估，大家按照我的思路去评估。</p>
<p>一条消息的大小 <code>50kb -&gt; 1kb 500byte 1M</code></p>
<p>ip 主机名</p>
<ul>
<li>192.168.0.100 hadoop1</li>
<li>192.168.0.101 hadoop2</li>
<li>192.168.0.102 hadoop3</li>
</ul>
<p>主机的规划：kafka集群架构的时候：主从式的架构：</p>
<ul>
<li>controller -&gt; 通过zk集群来管理整个集群的元数据。</li>
</ul>
<p>zookeeper集群</p>
<ul>
<li>hadoop1</li>
<li>hadoop2</li>
<li>hadoop3</li>
</ul>
<p>kafka集群</p>
<ul>
<li>理论上来讲，我们不应该把kafka的服务于zk的服务安装在一起。</li>
<li>但是我们这儿服务器有限。所以我们kafka集群也是安装在hadoop1 haadoop2 hadoop3</li>
</ul>
<h4 id="11-8-zookeeper集群搭建"><a href="#11-8-zookeeper集群搭建" class="headerlink" title="11.8 zookeeper集群搭建"></a>11.8 zookeeper集群搭建</h4><h4 id="11-9-核心参数详解"><a href="#11-9-核心参数详解" class="headerlink" title="11.9 核心参数详解"></a>11.9 核心参数详解</h4><h4 id="11-10-集群压力测试"><a href="#11-10-集群压力测试" class="headerlink" title="11.10 集群压力测试"></a>11.10 集群压力测试</h4><h2 id="12、kafka运维"><a href="#12、kafka运维" class="headerlink" title="12、kafka运维"></a>12、kafka运维</h2><h4 id="12-1-常见运维工具介绍"><a href="#12-1-常见运维工具介绍" class="headerlink" title="12.1 常见运维工具介绍"></a>12.1 常见运维工具介绍</h4><p>KafkaManager — 页面管理工具</p>
<h4 id="12-2-常见运维命令"><a href="#12-2-常见运维命令" class="headerlink" title="12.2 常见运维命令"></a>12.2 常见运维命令</h4><p>场景一：topic数据量太大，要增加topic数</p>
<p>一开始创建主题的时候，数据量不大，给的分区数不多。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-topics.sh --create --zookeeper hadoop1:<span class="number">2181</span>,hadoop2:<span class="number">2181</span>,hadoop3:<span class="number">2181</span> --replication-factor <span class="number">1</span> --partitions <span class="number">1</span> --topic test6</span><br><span class="line"></span><br><span class="line">kafka-topics.sh --alter --zookeeper hadoop1:<span class="number">2181</span>,hadoop2:<span class="number">2181</span>,hadoop3:<span class="number">2181</span> --partitions <span class="number">3</span> --topic test6</span><br></pre></td></tr></table></figure>

<p>broker id：</p>
<ul>
<li>hadoop1:0</li>
<li>hadoop2:1</li>
<li>hadoop3:2</li>
</ul>
<p>假设一个partition有三个副本：partition0：</p>
<blockquote>
<p>a,b,c</p>
</blockquote>
<ul>
<li>a：leader partition</li>
<li>b，c:follower partition</li>
</ul>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ISR:&#123;a,b,c&#125;</span><br></pre></td></tr></table></figure>

<p>如果一个follower分区 超过10秒 没有向leader partition去拉取数据，那么这个分区就从ISR列表里面移除。</p>
<p>场景二：核心topic增加副本因子</p>
<p>如果对核心业务数据需要增加副本因子</p>
<p>vim test.json脚本，将下面一行json脚本保存</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#123;“version”:<span class="number">1</span>,“partitions”:[&#123;“topic”:“test6”,“partition”:<span class="number">0</span>,“replicas”:[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]&#125;,&#123;“topic”:“test6”,“partition”:<span class="number">1</span>,“replicas”:[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]&#125;,&#123;“topic”:“test6”,“partition”:<span class="number">2</span>,“replicas”:[<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]&#125;]&#125;</span><br></pre></td></tr></table></figure>

<p>执行上面json脚本：</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kafka-reassign-partitions.sh --zookeeper hadoop1:<span class="number">2181</span>,hadoop2:<span class="number">2181</span>,hadoop3:<span class="number">2181</span> --reassignment-json-file test.json --execute</span><br></pre></td></tr></table></figure>

<p>场景三：负载不均衡的topic，手动迁移</p>
<p>vi topics-to-move.json</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&#123;“topics”: [&#123;“topic”: “test01”&#125;, &#123;“topic”: “test02”&#125;], “version”: <span class="number">1</span>&#125; </span><br><span class="line"><span class="comment">// 把你所有的topic都写在这里</span></span><br><span class="line"></span><br><span class="line">kafka-reassgin-partitions.sh --zookeeper hadoop1:<span class="number">2181</span>,hadoop2:<span class="number">2181</span>,hadoop3:<span class="number">2181</span> --topics-to-move-json-file topics-to-move.json --broker-list “<span class="number">5</span>,<span class="number">6</span>” --generate</span><br><span class="line"><span class="comment">// 把你所有的包括新加入的broker机器都写在这里，就会说是把所有的partition均匀的分散在各个broker上，包括新进来的broker</span></span><br></pre></td></tr></table></figure>

<p>此时会生成一个迁移方案，可以保存到一个文件里去：expand-cluster-reassignment.json</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka-reassign-partitions.sh --zookeeper hadoop01:<span class="number">2181</span>,hadoop02:<span class="number">2181</span>,hadoop03:<span class="number">2181</span> --reassignment-json-file expand-cluster-reassignment.json --execute</span><br><span class="line"></span><br><span class="line">kafka-reassign-partitions.sh --zookeeper hadoop01:<span class="number">2181</span>,hadoop02:<span class="number">2181</span>,hadoop03:<span class="number">2181</span> --reassignment-json-file expand-cluster-reassignment.json --verify</span><br></pre></td></tr></table></figure>

<p>这种数据迁移操作一定要在晚上低峰的时候来做，因为他会在机器之间迁移数据，非常的占用带宽资源</p>
<ul>
<li>generate: 根据给予的Topic列表和Broker列表生成迁移计划。generate并不会真正进行消息迁移，而是将消息迁移计划计算出来，供execute命令使用。</li>
<li>execute: 根据给予的消息迁移计划进行迁移。</li>
<li>verify: 检查消息是否已经迁移完成。</li>
</ul>
<p>场景四：如果某个broker leader partition过多</p>
<p>正常情况下，我们的leader partition在服务器之间是负载均衡。</p>
<ul>
<li>hadoop1 4</li>
<li>hadoop2 1</li>
<li>hadoop3 1</li>
</ul>
<p>现在各个业务方可以自行申请创建topic，分区数量都是自动分配和后续动态调整的，kafka本身会自动把leader partition均匀分散在各个机器上，这样可以保证每台机器的读写吞吐量都是均匀的。</p>
<p>但是也有例外，那就是如果某些broker宕机，会导致leader partition过于集中在其他少部分几台broker上，这会导致少数几台broker的读写请求压力过高，其他宕机的broker重启之后都是folloer partition，读写请求很低。</p>
<p>造成集群负载不均衡有一个参数，<code>auto.leader.rebalance.enable</code>，默认是true，每隔300秒（<code>leader.imbalance.check.interval.seconds</code>）检查leader负载是否平衡</p>
<p>如果一台broker上的不均衡的leader超过了10%，<code>leader.imbalance.per.broker.percentage</code>，就会对这个broker进行选举。</p>
<p>配置参数：</p>
<ul>
<li><code>auto.leader.rebalance.enable</code> 默认是true</li>
<li><code>leader.imbalance.per.broker.percentage</code>: 每个broker允许的不平衡的leader的比率。如果每个broker超过了这个值，控制器会触发leader的平衡。这个值表示百分比。10%</li>
<li><code>leader.imbalance.check.interval.seconds</code>：默认值300秒</li>
</ul>
<h2 id="13、Kafka生产者"><a href="#13、Kafka生产者" class="headerlink" title="13、Kafka生产者"></a>13、Kafka生产者</h2><h4 id="13-1-消费者发送消息原理"><a href="#13-1-消费者发送消息原理" class="headerlink" title="13.1 消费者发送消息原理"></a>13.1 消费者发送消息原理</h4><p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/10.png"></p>
<h4 id="13-2-消费者发送消息原理—基础案例演示"><a href="#13-2-消费者发送消息原理—基础案例演示" class="headerlink" title="13.2 消费者发送消息原理—基础案例演示"></a>13.2 消费者发送消息原理—基础案例演示</h4><p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/11.png"></p>
<h4 id="13-3-如何提升吞吐量"><a href="#13-3-如何提升吞吐量" class="headerlink" title="13.3 如何提升吞吐量"></a>13.3 如何提升吞吐量</h4><p>如何提升吞吐量：参数一：buffer.memory：</p>
<p>设置发送消息的缓冲区，默认值是33554432，就是32MB</p>
<p>参数二：compression.type：</p>
<p>默认是none，不压缩，但是也可以使用lz4压缩，效率还是不错的，压缩之后可以减小数据量，提升吞吐量，但是会加大producer端的cpu开销</p>
<p>参数三：batch.size：</p>
<ul>
<li>设置batch的大小，如果batch太小，会导致频繁网络请求，吞吐量下降；</li>
<li>如果batch太大，会导致一条消息需要等待很久才能被发送出去，而且会让内存缓冲区有很大压力，过多数据缓冲在内存里，默认值是：16384，就是16kb，也就是一个batch满了16kb就发送出去，一般在实际生产环境，这个batch的值可以增大一些来提升吞吐量，如果一个批次设置大了，会有延迟。一般根据一条消息大小来设置。</li>
<li>如果我们消息比较少。配合使用的参数linger.ms，这个值默认是0，意思就是消息必须立即被发送，但是这是不对的，一般设置一个100毫秒之类的，这样的话就是说，这个消息被发送出去后进入一个batch，如果100毫秒内，这个batch满了16kb，自然就会发送出去。</li>
</ul>
<h4 id="13-4-如何处理异常"><a href="#13-4-如何处理异常" class="headerlink" title="13.4 如何处理异常"></a>13.4 如何处理异常</h4><p>1、LeaderNotAvailableException：</p>
<p>这个就是如果某台机器挂了，此时leader副本不可用，会导致你写入失败，要等待其他follower副本切换为leader副本之后，才能继续写入，此时可以重试发送即可；如果说你平时重启kafka的broker进程，肯定会导致leader切换，一定会导致你写入报错，是<code>LeaderNotAvailableException</code>。</p>
<p>2、NotControllerException：</p>
<p>这个也是同理，如果说Controller所在Broker挂了，那么此时会有问题，需要等待Controller重新选举，此时也是一样就是重试即可。</p>
<p>3、NetworkException：网络异常 timeout</p>
<ul>
<li>配置retries参数，他会自动重试的</li>
<li>但是如果重试几次之后还是不行，就会提供Exception给我们来处理了,我们获取到异常以后，再对这个消息进行单独处理。我们会有备用的链路。发送不成功的消息发送到Redis或者写到文件系统中，甚至是丢弃。</li>
</ul>
<h4 id="13-5-重试机制"><a href="#13-5-重试机制" class="headerlink" title="13.5 重试机制"></a>13.5 重试机制</h4><p>重试会带来一些问题：</p>
<p>消息重复</p>
<p>有的时候一些leader切换之类的问题，需要进行重试，设置retries即可，但是消息重试会导致,重复发送的问题，比如说网络抖动一下导致他以为没成功，就重试了，其实人家都成功了.</p>
<p>消息乱序消息重试是可能导致消息的乱序的，因为可能排在你后面的消息都发送出去了。所以可以使用” <code>max.in.flight.requests.per.connection</code>“参数设置为1，这样可以保证producer同一时间只能发送一条消息。</p>
<p>两次重试的间隔默认是100毫秒，用”<code>retry.backoff.ms</code>“来进行设置，基本上在开发过程中，靠重试机制基本就可以搞定95%的异常问题。</p>
<h4 id="13-6-ACK参数详解"><a href="#13-6-ACK参数详解" class="headerlink" title="13.6 ACK参数详解"></a>13.6 ACK参数详解</h4><p>producer端</p>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">request.required.acks</span>=<span class="number">0</span>；</span><br></pre></td></tr></table></figure>

<ul>
<li>只要请求已发送出去，就算是发送完了，不关心有没有写成功。</li>
<li>性能很好，如果是对一些日志进行分析，可以承受丢数据的情况，用这个参数，性能会很好。</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">request.required.acks</span>=<span class="number">1</span>；</span><br></pre></td></tr></table></figure>

<ul>
<li>发送一条消息，当leader partition写入成功以后，才算写入成功。</li>
<li>不过这种方式也有丢数据的可能。</li>
</ul>
<figure class="highlight ini"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">request.required.acks</span>=-<span class="number">1</span>；</span><br></pre></td></tr></table></figure>

<ul>
<li>需要ISR列表里面，所有副本都写完以后，这条消息才算写入成功。</li>
<li>ISR：1个副本。1 leader partition 1 follower partition</li>
</ul>
<p>kafka服务端：</p>
<figure class="highlight apache"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">min</span>.insync.replicas：<span class="number">1</span></span><br></pre></td></tr></table></figure>

<p>如果我们不设置的话，默认这个值是1，一个leader partition会维护一个ISR列表，这个值就是限制ISR列表里面，至少得有几个副本，比如这个值是2，那么当ISR列表里面只有一个副本的时候。往这个分区插入数据的时候会报错。</p>
<p>设计一个不丢数据的方案：</p>
<ul>
<li>分区副本 &gt;=2</li>
<li>acks = -1</li>
<li>min.insync.replicas &gt;=2</li>
</ul>
<p>还有可能就是发送有异常：对异常进行处理</p>
<h4 id="13-7-自定义分区"><a href="#13-7-自定义分区" class="headerlink" title="13.7 自定义分区"></a>13.7 自定义分区</h4><p>分区：</p>
<ul>
<li>没有设置key</li>
</ul>
<p>我们的消息就会被轮训的发送到不同的分区。</p>
<ul>
<li>设置了key</li>
</ul>
<p>kafka自带的分区器，会根据key计算出来一个hash值，这个hash值会对应某一个分区。</p>
<p>如果key相同的，那么hash值必然相同，key相同的值，必然是会被发送到同一个分区。</p>
<p>但是有些比较特殊的时候，我们就需要自定义分区</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">HotDataPartitioner</span> <span class="keyword">implements</span> <span class="title">Partitioner</span> </span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Random random;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">configure</span><span class="params">(Map&lt;String, ?&gt; configs)</span> </span>&#123;</span><br><span class="line">        random = <span class="keyword">new</span> Random();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">partition</span><span class="params">(String topic, Object keyObj, <span class="keyword">byte</span>[] keyBytes, Object value, <span class="keyword">byte</span>[] valueBytes, Cluster cluster)</span> </span>&#123;</span><br><span class="line">        String key = (String)keyObj;</span><br><span class="line">        List partitionInfoList = cluster.availablePartitionsForTopic(topic);</span><br><span class="line"><span class="comment">//获取到分区的个数 0,1，2</span></span><br><span class="line">        <span class="keyword">int</span> partitionCount = partitionInfoList.size();</span><br><span class="line"><span class="comment">//最后一个分区</span></span><br><span class="line">        <span class="keyword">int</span> hotDataPartition = partitionCount - <span class="number">1</span>;</span><br><span class="line">        <span class="keyword">return</span> !key.contains(“hot_data”) ? random.nextInt(partitionCount - <span class="number">1</span>) : hotDataPartition;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>如何使用：</p>
<p>配置上这个类即可：<code>props.put(”partitioner.class”, “com.zhss.HotDataPartitioner”);</code></p>
<h4 id="13-8-综合案例演示"><a href="#13-8-综合案例演示" class="headerlink" title="13.8 综合案例演示"></a>13.8 综合案例演示</h4><p>需求分析：</p>
<blockquote>
<p>电商背景 -》 二手的电商平台</p>
<p>【欢乐送】的项目，用户购买了东西以后会有【星星】，用星星去换物品。一块钱一个星星。</p>
</blockquote>
<p>订单系统（消息的生产），发送一条消息（支付订单，取消订单） -&gt; Kafka &lt;- 会员系统，从kafak里面去消费数据，找到对应用户消费的金额，然后给该用户更新星星的数量。</p>
<p>分析一下：</p>
<p>发送消息的时候，可以指定key，也可以不指定key。</p>
<p>1)如果不指定key</p>
<ul>
<li>zhangsan -&gt;下订单 -&gt; 100 -&gt; +100</li>
<li>zhangsan -&gt; 取消订单 -&gt; -100 -&gt; -100</li>
<li>会员系统消费数据的时候，有可能先消费到的是 取消订单的数据。</li>
</ul>
<p>2)如果指定key,key -&gt; hash（数字） -&gt; 对应分区号 -&gt; 发送到对应的分区里面。</p>
<ul>
<li>如果key相同的 -&gt; 数据肯定会被发送到同一个分区（有序的）</li>
</ul>
<p>这个项目需要指定key，把用户的id指定为key.</p>
<h2 id="14、Kafka消费者"><a href="#14、Kafka消费者" class="headerlink" title="14、Kafka消费者"></a>14、Kafka消费者</h2><h4 id="14-1-消费组概念"><a href="#14-1-消费组概念" class="headerlink" title="14.1 消费组概念"></a>14.1 消费组概念</h4><p>groupid相同就属于同一个消费组</p>
<p>1）每个consumer都要属于一个consumer.group，就是一个消费组，topic的一个分区只会分配给一个消费组下的一个consumer来处理，每个consumer可能会分配多个分区，也有可能某个consumer没有分配到任何分区。</p>
<p>2）如果想要实现一个广播的效果，那只需要使用不同的group id去消费就可以。</p>
<p>topicA:</p>
<ul>
<li>partition0、partition1</li>
</ul>
<p>groupA：</p>
<ul>
<li>consumer1:消费 partition0</li>
<li>consuemr2:消费 partition1</li>
<li>consuemr3:消费不到数据</li>
</ul>
<p>groupB:</p>
<ul>
<li>consuemr3:消费到partition0和partition1</li>
</ul>
<p>3）如果consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会把一些分区重新交还给他</p>
<h4 id="14-2-基础案例演示"><a href="#14-2-基础案例演示" class="headerlink" title="14.2 基础案例演示"></a>14.2 基础案例演示</h4><p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/12.png"></p>
<h4 id="14-3-偏移量管理"><a href="#14-3-偏移量管理" class="headerlink" title="14.3 偏移量管理"></a>14.3 偏移量管理</h4><p>每个consumer内存里数据结构保存对每个topic的每个分区的消费offset，定期会提交offset，老版本是写入zk，但是那样高并发请求zk是不合理的架构设计，zk是做分布式系统的协调的，轻量级的元数据存储，不能负责高并发读写，作为数据存储。</p>
<p>现在新的版本提交offset发送给kafka内部topic：<code>__consumer_offsets</code>，提交过去的时候， key是<code>group.id+topic+分区号</code>，value就是当前offset的值，每隔一段时间，kafka内部会对这个topic进行compact(合并)，也就是每个group.id+topic+分区号就保留最新数据。</p>
<p><code>__consumer_offsets</code>可能会接收高并发的请求，所以默认分区50个(leader partitiron -&gt; 50 kafka)，这样如果你的kafka部署了一个大的集群，比如有50台机器，就可以用50台机器来抗offset提交的请求压力。</p>
<ul>
<li>消费者 -&gt; broker端的数据</li>
<li>message -&gt; 磁盘 -&gt; offset 顺序递增</li>
<li>从哪儿开始消费？-&gt; offset</li>
<li>消费者（offset）</li>
</ul>
<h4 id="14-4-偏移量监控工具介绍"><a href="#14-4-偏移量监控工具介绍" class="headerlink" title="14.4 偏移量监控工具介绍"></a>14.4 偏移量监控工具介绍</h4><p>web页面管理的一个管理软件(kafka Manager)</p>
<ul>
<li>修改bin/kafka-run-class.sh脚本，第一行增加<code>JMX_PORT=9988</code></li>
<li>重启kafka进程</li>
</ul>
<p>另一个软件：主要监控的consumer的偏移量。</p>
<p>就是一个jar包<code>java -cp KafkaOffsetMonitor-assembly-0.3.0-SNAPSHOT.jar</code></p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">com<span class="selector-class">.quantifind</span><span class="selector-class">.kafka</span><span class="selector-class">.offsetapp</span>.OffsetGetterWeb</span><br></pre></td></tr></table></figure>

<ul>
<li>offsetStorage kafka \（根据版本：偏移量存在kafka就填kafka，存在zookeeper就填zookeeper）</li>
<li>zk hadoop1:2181</li>
<li>port 9004</li>
<li>refresh 15.seconds</li>
<li>retain 2.days</li>
</ul>
<p>写了一段程序 ,消费kafka里面的数据（consumer，处理数据 -&gt; 业务代码） -&gt; Kafka 如何去判断你的这段代码真的是实时的去消费的呢？</p>
<p>延迟几亿条数据 -&gt; 阈值（20万条的时候 发送一个告警。）</p>
<h4 id="14-5-消费异常感知"><a href="#14-5-消费异常感知" class="headerlink" title="14.5 消费异常感知"></a>14.5 消费异常感知</h4><p><code>heartbeat.interval.ms</code>：</p>
<ul>
<li>consumer心跳时间间隔，必须得与coordinator保持心跳才能知道consumer是否故障了，</li>
<li>然后如果故障之后，就会通过心跳下发rebalance的指令给其他的consumer通知他们进行rebalance的操作</li>
</ul>
<p><code>session.timeout.ms</code>：</p>
<ul>
<li>kafka多长时间感知不到一个consumer就认为他故障了，默认是10秒</li>
</ul>
<p><code>max.poll.interval.ms</code>：</p>
<ul>
<li>如果在两次poll操作之间，超过了这个时间，那么就会认为这个consume处理能力太弱了，会被踢出消费组，分区分配给别人去消费，一般来说结合业务处理的性能来设置就可以了。</li>
</ul>
<h4 id="14-6-核心参数解释"><a href="#14-6-核心参数解释" class="headerlink" title="14.6 核心参数解释"></a>14.6 核心参数解释</h4><p><code>fetch.max.bytes</code>：</p>
<p>获取一条消息最大的字节数，一般建议设置大一些，默认是1M 其实我们在之前多个地方都见到过这个类似的参数，意思就是说一条信息最大能多大？</p>
<ol>
<li>Producer：发送的数据，一条消息最大多大， -&gt; 10M</li>
<li>Broker：存储数据，一条消息最大能接受多大 -&gt; 10M</li>
<li>Consumer：</li>
</ol>
<p><code>max.poll.records</code>:</p>
<p>一次poll返回消息的最大条数，默认是500条</p>
<p><code>connection.max.idle.ms</code>：</p>
<p>consumer跟broker的socket连接如果空闲超过了一定的时间，此时就会自动回收连接，但是下次消费就要重新建立socket连接，这个建议设置为-1，不要去回收</p>
<p><code>enable.auto.commit</code>:</p>
<p>开启自动提交偏移量</p>
<p><code>auto.commit.interval.ms</code>:</p>
<p>每隔多久提交一次偏移量，默认值5000毫秒</p>
<p><code>auto.offset.reset</code>：</p>
<ul>
<li>earliest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费</li>
<li>latest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据</li>
<li>none：topic各分区都存在已提交的offset时，从offset后开始消费；只要有一个分区不存在已提交的offset，则抛出异常</li>
</ul>
<h4 id="14-7-综合案例演示"><a href="#14-7-综合案例演示" class="headerlink" title="14.7 综合案例演示"></a>14.7 综合案例演示</h4><p>引入案例：二手电商平台（欢乐送），根据用户消费的金额，对用户星星进行累计。</p>
<ul>
<li>订单系统（生产者） -&gt; Kafka集群里面发送了消息。</li>
<li>会员系统（消费者） -&gt; Kafak集群里面消费消息，对消息进行处理。</li>
</ul>
<h4 id="14-8-group-coordinator原理"><a href="#14-8-group-coordinator原理" class="headerlink" title="14.8 group coordinator原理"></a>14.8 group coordinator原理</h4><p>面试题：消费者是如何实现rebalance的？— 根据coordinator实现</p>
<h5 id="什么是coordinator"><a href="#什么是coordinator" class="headerlink" title="什么是coordinator"></a>什么是coordinator</h5><p>每个consumer group都会选择一个broker作为自己的coordinator，他是负责监控这个消费组里的各个消费者的心跳，以及判断是否宕机，然后开启rebalance的</p>
<h5 id="如何选择coordinator机器"><a href="#如何选择coordinator机器" class="headerlink" title="如何选择coordinator机器"></a>如何选择coordinator机器</h5><p>首先对groupId进行hash（数字），接着对<code>__consumer_offsets</code>的分区数量取模，默认是50，<code>_consumer_offsets</code>的分区数可以通过<code>offsets.topic.num.partitions</code>来设置，找到分区以后，这个分区所在的broker机器就是coordinator机器。</p>
<p>比如说：groupId，“myconsumer_group” -&gt; hash值（数字）-&gt; 对50取模 -&gt; 8<code>__consumer_offsets</code> 这个主题的8号分区在哪台broker上面，那一台就是coordinator 就知道这个consumer group下的所有的消费者提交offset的时候是往哪个分区去提交offset，</p>
<p>运行流程</p>
<ul>
<li>每个consumer都发送JoinGroup请求到Coordinator，</li>
<li>然后Coordinator从一个consumer group中选择一个consumer作为leader，</li>
<li>把consumer group情况发送给这个leader，</li>
<li>接着这个leader会负责制定消费方案，</li>
<li>通过SyncGroup发给Coordinator</li>
<li>接着Coordinator就把消费方案下发给各个consumer，他们会从指定的分区的</li>
</ul>
<p>leader broker开始进行socket连接以及消费消息</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/13.png"></p>
<h4 id="14-9-rebalance策略"><a href="#14-9-rebalance策略" class="headerlink" title="14.9 rebalance策略"></a>14.9 rebalance策略</h4><p>consumer group靠coordinator实现了Rebalance</p>
<p>这里有三种rebalance的策略：range、round-robin、sticky</p>
<p>比如我们消费的一个主题有12个分区：</p>
<figure class="highlight smali"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">p0,p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,p11</span><br></pre></td></tr></table></figure>

<p>假设我们的消费者组里面有三个消费者</p>
<p>range策略</p>
<ul>
<li>range策略就是按照partiton的序号范围</li>
<li>p0~3 consumer1</li>
<li>p4~7 consumer2</li>
<li>p8~11 consumer3</li>
<li>默认就是这个策略；</li>
</ul>
<p>round-robin策略</p>
<ul>
<li>就是轮询分配</li>
<li>consumer1:0,3,6,9</li>
<li>consumer2:1,4,7,10</li>
<li>consumer3:2,5,8,11</li>
</ul>
<p>但是前面的这两个方案有个问题：12 -&gt; 2 每个消费者会消费6个分区</p>
<p>假设consuemr1挂了:p0-5分配给consumer2,p6-11分配给consumer3，这样的话，原本在consumer2上的的p6,p7分区就被分配到了 consumer3上。</p>
<p>sticky策略</p>
<p>最新的一个sticky策略，就是说尽可能保证在rebalance的时候，让原本属于这个consumer的分区还是属于他们，然后把多余的分区再均匀分配过去，这样尽可能维持原来的分区分配的策略</p>
<ul>
<li>consumer1：0-3</li>
<li>consumer2: 4-7</li>
<li>consumer3: 8-11</li>
</ul>
<p>假设consumer3挂了</p>
<ul>
<li>consumer1：0-3，+8,9</li>
<li>consumer2: 4-7，+10,11</li>
</ul>
<h2 id="15、Broker管理"><a href="#15、Broker管理" class="headerlink" title="15、Broker管理"></a>15、Broker管理</h2><h4 id="15-1-Leo、hw含义"><a href="#15-1-Leo、hw含义" class="headerlink" title="15.1 Leo、hw含义"></a>15.1 Leo、hw含义</h4><ul>
<li>Kafka的核心原理</li>
<li>如何去评估一个集群资源</li>
<li>搭建了一套kafka集群 -》 介绍了简单的一些运维管理的操作。</li>
<li>生产者（使用，核心的参数）</li>
<li>消费者（原理，使用的，核心参数）</li>
<li>broker内部的一些原理，核心的概念：LEO，HW</li>
</ul>
<blockquote>
<p>LEO：是跟offset偏移量有关系。</p>
</blockquote>
<p>LEO：</p>
<p>在kafka里面，无论leader partition还是follower partition统一都称作副本（replica）。</p>
<p>每次partition接收到一条消息，都会更新自己的LEO，也就是log end offset，LEO其实就是最新的offset + 1</p>
<p>HW：高水位</p>
<p>LEO有一个很重要的功能就是更新HW，如果follower和leader的LEO同步了，此时HW就可以更新</p>
<p>HW之前的数据对消费者是可见，消息属于commit状态。HW之后的消息消费者消费不到。</p>
<h4 id="15-2-Leo更新"><a href="#15-2-Leo更新" class="headerlink" title="15.2 Leo更新"></a>15.2 Leo更新</h4><p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/14.png"></p>
<p>15.3 hw更新</p>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/15.png"></p>
<h4 id="15-4-controller如何管理整个集群"><a href="#15-4-controller如何管理整个集群" class="headerlink" title="15.4 controller如何管理整个集群"></a>15.4 controller如何管理整个集群</h4><p>1: 竞争controller的</p>
<ul>
<li><code>/controller/id</code></li>
</ul>
<p>2：controller服务监听的目录：</p>
<ul>
<li><code>/broker/ids/</code> 用来感知 broker上下线</li>
<li><code>/broker/topics/</code> 创建主题，我们当时创建主题命令，提供的参数，ZK地址。</li>
<li><code>/admin/reassign_partitions</code> 分区重分配</li>
</ul>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/16.png" alt="img"></p>
<h4 id="15-5-延时任务"><a href="#15-5-延时任务" class="headerlink" title="15.5 延时任务"></a>15.5 延时任务</h4><blockquote>
<p>kafka的延迟调度机制（扩展知识）</p>
</blockquote>
<p>我们先看一下kafka里面哪些地方需要有任务要进行延迟调度。</p>
<p>第一类延时的任务：</p>
<p>比如说producer的acks=-1，必须等待leader和follower都写完才能返回响应。</p>
<p>有一个超时时间，默认是30秒（request.timeout.ms）。</p>
<p>所以需要在写入一条数据到leader磁盘之后，就必须有一个延时任务，到期时间是30秒延时任务 放到DelayedOperationPurgatory（延时管理器）中。</p>
<p>假如在30秒之前如果所有follower都写入副本到本地磁盘了，那么这个任务就会被自动触发苏醒，就可以返回响应结果给客户端了，否则的话，这个延时任务自己指定了最多是30秒到期，如果到了超时时间都没等到，就直接超时返回异常。</p>
<p>第二类延时的任务：</p>
<p>follower往leader拉取消息的时候，如果发现是空的，此时会创建一个延时拉取任务</p>
<p>延时时间到了之后（比如到了100ms），就给follower返回一个空的数据，然后follower再次发送请求读取消息，但是如果延时的过程中(还没到100ms)，leader写入了消息，这个任务就会自动苏醒，自动执行拉取任务。</p>
<p>海量的延时任务，需要去调度。</p>
<h4 id="15-6-时间轮机制"><a href="#15-6-时间轮机制" class="headerlink" title="15.6 时间轮机制"></a>15.6 时间轮机制</h4><p>1.什么会有要设计时间轮？</p>
<p>Kafka内部有很多延时任务，没有基于JDK Timer来实现，那个插入和删除任务的时间复杂度是O(nlogn)，而是基于了自己写的时间轮来实现的，时间复杂度是O(1)，依靠时间轮机制，延时任务插入和删除，O(1)</p>
<p>2.时间轮是什么？</p>
<p>其实时间轮说白其实就是一个数组。</p>
<ul>
<li><p>tickMs:时间轮间隔 1ms</p>
</li>
<li><p>wheelSize：时间轮大小 20</p>
</li>
<li><p>interval：timckMS * whellSize，一个时间轮的总的时间跨度。20ms</p>
</li>
<li><p>currentTime：当时时间的指针。</p>
</li>
<li><ul>
<li>a:因为时间轮是一个数组，所以要获取里面数据的时候，靠的是index，时间复杂度是O(1)</li>
<li>b:数组某个位置上对应的任务，用的是双向链表存储的，往双向链表里面插入，删除任务，时间复杂度也是O（1）</li>
</ul>
</li>
</ul>
<ol start="3">
<li>多层级的时间轮</li>
</ol>
<p>比如：要插入一个110毫秒以后运行的任务。</p>
<ul>
<li><p>tickMs:时间轮间隔 20ms</p>
</li>
<li><p>wheelSize：时间轮大小 20</p>
</li>
<li><p>interval：timckMS * whellSize，一个时间轮的总的时间跨度。20ms</p>
</li>
<li><p>currentTime：当时时间的指针。</p>
</li>
<li><ul>
<li>第一层时间轮：1ms * 20</li>
<li>第二层时间轮：20ms * 20</li>
<li>第三层时间轮：400ms * 20</li>
</ul>
</li>
</ul>
<p><img src="https://gitee.com/chenjiabing666/BlogImage/raw/master/%E4%B8%A4%E4%B8%87%E5%AD%97%E6%90%9E%E6%87%82kafka/17.png"></p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者：</strong>
    不才陈某  |  微信公众号【码猿技术专栏】
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="https://chenjiabing666.github.io/2021/08/13/%E4%B8%A4%E4%B8%87%E5%AD%97%E9%95%BF%E6%96%87%EF%BC%8C%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82Kafka/" title="两万字长文，彻底搞懂Kafka">https://chenjiabing666.github.io/2021/08/13/两万字长文，彻底搞懂Kafka/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fab fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
  <li class="post-copyright-license">
    并保留本声明和上方二维码。感谢您的阅读和支持！
  </li>
</ul>
</div>

        

  <div class="followme">
    <p>欢迎关注我的其它发布渠道</p>

    <div class="social-list">

        <div class="social-item">
          <a target="_blank" class="social-link" href="/images/wechat_channel.jpg">
            <span class="icon">
              <i class="fab fa-weixin"></i>
            </span>

            <span class="label">微信公众号</span>
          </a>
        </div>
    </div>
  </div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/kafka/" rel="tag"># kafka</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2021/08/12/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1%E6%A1%86%E6%9E%B6%E9%80%89%E5%9E%8B%EF%BC%8C%E4%BD%A0%E7%9F%A5%E9%81%93%E5%93%AA%E5%87%A0%E7%A7%8D%EF%BC%9F/" rel="prev" title="分布式定时任务框架选型，你知道哪几种？">
      <i class="fa fa-chevron-left"></i> 分布式定时任务框架选型，你知道哪几种？
    </a></div>
      <div class="post-nav-item">
    <a href="/2021/08/15/5%E7%A7%8D%E5%85%A8%E5%B1%80ID%E7%94%9F%E6%88%90%E6%96%B9%E5%BC%8F%E3%80%81%E4%BC%98%E7%BC%BA%E7%82%B9%E5%8F%8A%E6%94%B9%E8%BF%9B%E6%96%B9%E6%A1%88%EF%BC%8C%E4%BD%A0%E7%9F%A5%E9%81%93%E5%93%AA%E5%87%A0%E7%A7%8D%EF%BC%9F/" rel="next" title="5种全局ID生成方式、优缺点及改进方案，你知道哪几种？">
      5种全局ID生成方式、优缺点及改进方案，你知道哪几种？ <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          
    <div class="comments" id="valine-comments"></div>

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

		  <script src="https://readmore.openwrite.cn/js/readmore.js" type="text/javascript"></script>
<script>
    const btw = new BTWPlugin();
    btw.init({
        id: 'container',
        blogId: '27513-1629019452485-311',
        name: '码猿技术专栏',
        qrcode: 'https://gitee.com/chenjiabing666/BlogImage/raw/master/@Async%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%BB%BA%E8%AE%AE%E4%BD%BF%E7%94%A8/16.jpg',
        keyword: 'vip',
    });
</script>
        </div>
		</div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#1%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E6%9C%89%E6%B6%88%E6%81%AF%E7%B3%BB%E7%BB%9F"><span class="nav-text">1、为什么有消息系统</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#1%E3%80%81%E8%A7%A3%E8%80%A6%E5%90%88"><span class="nav-text">1、解耦合</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#2%E3%80%81%E5%BC%82%E6%AD%A5%E5%A4%84%E7%90%86"><span class="nav-text">2、异步处理</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#3%E3%80%81%E6%B5%81%E9%87%8F%E7%9A%84%E6%8E%A7%E5%88%B6"><span class="nav-text">3、流量的控制</span></a></li></ol></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2%E3%80%81Kafka%E6%A0%B8%E5%BF%83%E6%A6%82%E5%BF%B5"><span class="nav-text">2、Kafka核心概念</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3%E3%80%81Kafka%E7%9A%84%E9%9B%86%E7%BE%A4%E6%9E%B6%E6%9E%84"><span class="nav-text">3、Kafka的集群架构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#4%E3%80%81Kafka%E7%A3%81%E7%9B%98%E9%A1%BA%E5%BA%8F%E5%86%99%E4%BF%9D%E8%AF%81%E5%86%99%E6%95%B0%E6%8D%AE%E6%80%A7%E8%83%BD"><span class="nav-text">4、Kafka磁盘顺序写保证写数据性能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#5%E3%80%81Kafka%E9%9B%B6%E6%8B%B7%E8%B4%9D%E6%9C%BA%E5%88%B6%E4%BF%9D%E8%AF%81%E8%AF%BB%E6%95%B0%E6%8D%AE%E9%AB%98%E6%80%A7%E8%83%BD"><span class="nav-text">5、Kafka零拷贝机制保证读数据高性能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#6%E3%80%81Kafka%E6%97%A5%E5%BF%97%E5%88%86%E6%AE%B5%E4%BF%9D%E5%AD%98"><span class="nav-text">6、Kafka日志分段保存</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#7%E3%80%81Kafka%E4%BA%8C%E5%88%86%E6%9F%A5%E6%89%BE%E5%AE%9A%E4%BD%8D%E6%95%B0%E6%8D%AE"><span class="nav-text">7、Kafka二分查找定位数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#8%E3%80%81%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BD%91%E7%BB%9C%E8%AE%BE%E8%AE%A1%EF%BC%88%E5%85%88%E4%BA%86%E8%A7%A3NIO%EF%BC%89"><span class="nav-text">8、高并发网络设计（先了解NIO）</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#9%E3%80%81Kafka%E5%86%97%E4%BD%99%E5%89%AF%E6%9C%AC%E4%BF%9D%E8%AF%81%E9%AB%98%E5%8F%AF%E7%94%A8"><span class="nav-text">9、Kafka冗余副本保证高可用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10%E3%80%81%E4%BC%98%E7%A7%80%E6%9E%B6%E6%9E%84%E6%80%9D%E8%80%83-%E6%80%BB%E7%BB%93"><span class="nav-text">10、优秀架构思考-总结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#11%E3%80%81Kafka%E7%94%9F%E4%BA%A7%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA"><span class="nav-text">11、Kafka生产环境搭建</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-1-%E9%9C%80%E6%B1%82%E5%9C%BA%E6%99%AF%E5%88%86%E6%9E%90"><span class="nav-text">11.1 需求场景分析</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-2-%E7%89%A9%E7%90%86%E6%9C%BA%E6%95%B0%E9%87%8F%E8%AF%84%E4%BC%B0"><span class="nav-text">11.2 物理机数量评估</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-3-%E7%A3%81%E7%9B%98%E9%80%89%E6%8B%A9"><span class="nav-text">11.3 磁盘选择</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-CPU%E5%8E%8B%E5%8A%9B%E8%AF%84%E4%BC%B0"><span class="nav-text">11.5 CPU压力评估</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-6-%E7%BD%91%E7%BB%9C%E9%9C%80%E6%B1%82%E8%AF%84%E4%BC%B0"><span class="nav-text">11.6 网络需求评估</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-7-%E9%9B%86%E7%BE%A4%E8%A7%84%E5%88%92"><span class="nav-text">11.7 集群规划</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-8-zookeeper%E9%9B%86%E7%BE%A4%E6%90%AD%E5%BB%BA"><span class="nav-text">11.8 zookeeper集群搭建</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-9-%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3"><span class="nav-text">11.9 核心参数详解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-10-%E9%9B%86%E7%BE%A4%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95"><span class="nav-text">11.10 集群压力测试</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12%E3%80%81kafka%E8%BF%90%E7%BB%B4"><span class="nav-text">12、kafka运维</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#12-1-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D"><span class="nav-text">12.1 常见运维工具介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#12-2-%E5%B8%B8%E8%A7%81%E8%BF%90%E7%BB%B4%E5%91%BD%E4%BB%A4"><span class="nav-text">12.2 常见运维命令</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#13%E3%80%81Kafka%E7%94%9F%E4%BA%A7%E8%80%85"><span class="nav-text">13、Kafka生产者</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#13-1-%E6%B6%88%E8%B4%B9%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E5%8E%9F%E7%90%86"><span class="nav-text">13.1 消费者发送消息原理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-2-%E6%B6%88%E8%B4%B9%E8%80%85%E5%8F%91%E9%80%81%E6%B6%88%E6%81%AF%E5%8E%9F%E7%90%86%E2%80%94%E5%9F%BA%E7%A1%80%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="nav-text">13.2 消费者发送消息原理—基础案例演示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-3-%E5%A6%82%E4%BD%95%E6%8F%90%E5%8D%87%E5%90%9E%E5%90%90%E9%87%8F"><span class="nav-text">13.3 如何提升吞吐量</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-4-%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86%E5%BC%82%E5%B8%B8"><span class="nav-text">13.4 如何处理异常</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-5-%E9%87%8D%E8%AF%95%E6%9C%BA%E5%88%B6"><span class="nav-text">13.5 重试机制</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-6-ACK%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3"><span class="nav-text">13.6 ACK参数详解</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-7-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA"><span class="nav-text">13.7 自定义分区</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#13-8-%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="nav-text">13.8 综合案例演示</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#14%E3%80%81Kafka%E6%B6%88%E8%B4%B9%E8%80%85"><span class="nav-text">14、Kafka消费者</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#14-1-%E6%B6%88%E8%B4%B9%E7%BB%84%E6%A6%82%E5%BF%B5"><span class="nav-text">14.1 消费组概念</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-2-%E5%9F%BA%E7%A1%80%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="nav-text">14.2 基础案例演示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-3-%E5%81%8F%E7%A7%BB%E9%87%8F%E7%AE%A1%E7%90%86"><span class="nav-text">14.3 偏移量管理</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-4-%E5%81%8F%E7%A7%BB%E9%87%8F%E7%9B%91%E6%8E%A7%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D"><span class="nav-text">14.4 偏移量监控工具介绍</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-5-%E6%B6%88%E8%B4%B9%E5%BC%82%E5%B8%B8%E6%84%9F%E7%9F%A5"><span class="nav-text">14.5 消费异常感知</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-6-%E6%A0%B8%E5%BF%83%E5%8F%82%E6%95%B0%E8%A7%A3%E9%87%8A"><span class="nav-text">14.6 核心参数解释</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-7-%E7%BB%BC%E5%90%88%E6%A1%88%E4%BE%8B%E6%BC%94%E7%A4%BA"><span class="nav-text">14.7 综合案例演示</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-8-group-coordinator%E5%8E%9F%E7%90%86"><span class="nav-text">14.8 group coordinator原理</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%80%E4%B9%88%E6%98%AFcoordinator"><span class="nav-text">什么是coordinator</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%A6%82%E4%BD%95%E9%80%89%E6%8B%A9coordinator%E6%9C%BA%E5%99%A8"><span class="nav-text">如何选择coordinator机器</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#14-9-rebalance%E7%AD%96%E7%95%A5"><span class="nav-text">14.9 rebalance策略</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#15%E3%80%81Broker%E7%AE%A1%E7%90%86"><span class="nav-text">15、Broker管理</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#15-1-Leo%E3%80%81hw%E5%90%AB%E4%B9%89"><span class="nav-text">15.1 Leo、hw含义</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-2-Leo%E6%9B%B4%E6%96%B0"><span class="nav-text">15.2 Leo更新</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-4-controller%E5%A6%82%E4%BD%95%E7%AE%A1%E7%90%86%E6%95%B4%E4%B8%AA%E9%9B%86%E7%BE%A4"><span class="nav-text">15.4 controller如何管理整个集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-5-%E5%BB%B6%E6%97%B6%E4%BB%BB%E5%8A%A1"><span class="nav-text">15.5 延时任务</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#15-6-%E6%97%B6%E9%97%B4%E8%BD%AE%E6%9C%BA%E5%88%B6"><span class="nav-text">15.6 时间轮机制</span></a></li></ol></li></ol></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="不才陈某"
      src="/images/header.jpg">
  <p class="site-author-name" itemprop="name">不才陈某</p>
  <div class="site-description" itemprop="description">本站是不才陈某的技术分享博客。内容涵盖Java后端技术、Spring Boot、微服务架构、系统安全、前端、系统监控等相关的研究与知识分享。</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">94</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">11</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">19</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://gitee.com/chenjiabing666/BlogImage/raw/master/myjszl_log.png" title="微信公众号 → https:&#x2F;&#x2F;gitee.com&#x2F;chenjiabing666&#x2F;BlogImage&#x2F;raw&#x2F;master&#x2F;myjszl_log.png" rel="noopener" target="_blank"><i class="fab fa-weixin fa-fw"></i>微信公众号</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://juejin.im/user/2506542244708072" title="掘金 → https:&#x2F;&#x2F;juejin.im&#x2F;user&#x2F;2506542244708072" rel="noopener" target="_blank"><i class="fab fa-google fa-fw"></i>掘金</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">不才陈某|公众号：码猿技术专栏</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  


<script>
NexT.utils.loadComments(document.querySelector('#valine-comments'), () => {
  NexT.utils.getScript('//unpkg.com/valine/dist/Valine.min.js', () => {
    var GUEST = ['nick', 'mail', 'link'];
    var guest = 'nick,mail,link';
    guest = guest.split(',').filter(item => {
      return GUEST.includes(item);
    });
    new Valine({
      el         : '#valine-comments',
      verify     : false,
      notify     : false,
      appId      : 'RtlQOgOT3M0hgyMeogykSQjT-gzGzoHsz',
      appKey     : 'vSCxLU88wnXVf0Pa8mwJrCPm',
      placeholder: "欢迎关注博主微信公众号【码猿技术专栏】",
      avatar     : 'mm',
      meta       : guest,
      pageSize   : '10' || 10,
      visitor    : false,
      lang       : '' || 'zh-cn',
      path       : location.pathname,
      recordIP   : false,
      serverURLs : ''
    });
  }, window.Valine);
});
</script>

</body>
</html>
